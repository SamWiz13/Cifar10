{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c14d558-8d5a-4006-a60d-f7f14c428295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0e9f9d-8dfe-4a04-89b6-5548704ea2ec",
   "metadata": {},
   "source": [
    "## Load train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e9d717e-7250-4a7e-9ce7-53f5c2a8bd89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "     # load dataset\n",
    "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "    \n",
    "     # one hot encode target values\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "# load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cd7d2a-7834-4c6c-80fd-b2c3c429d84b",
   "metadata": {},
   "source": [
    "## Scale pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d16c781a-ee0d-4697-b683-df9cf1345133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prep_pixels(train, test):\n",
    " # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    " # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    " # return normalized images\n",
    "    return train_norm, test_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5bc1c4-e211-4d9c-8eec-41c44b99a807",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9f161ce-838f-4ffd-8010-738a237e5aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1e50240aa10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "define_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae35f79-f0d7-4a71-807e-d11d77477d42",
   "metadata": {},
   "source": [
    "## Plot diagnostic learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68eba114-e525-40b2-9625-a996f02b1bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history):\n",
    "    \n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    \n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    \n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    pyplot.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07148021-7992-4328-b723-9fbbde71514b",
   "metadata": {},
   "source": [
    "## Run the test harness for evaluating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e02fd-c3a5-4811-a472-469ba700d477",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 1: 0.295158\n",
      "Accuracy after epoch 2: 0.405499\n",
      "Accuracy after epoch 3: 0.450637\n",
      "Accuracy after epoch 4: 0.485622\n",
      "Accuracy after epoch 5: 0.516441\n",
      "Accuracy after epoch 6: 0.536266\n",
      "Accuracy after epoch 7: 0.555932\n",
      "Accuracy after epoch 8: 0.572132\n",
      "Accuracy after epoch 9: 0.585289\n",
      "Accuracy after epoch 10: 0.596884\n",
      "Accuracy after epoch 11: 0.609060\n",
      "Accuracy after epoch 12: 0.617410\n",
      "Accuracy after epoch 13: 0.624299\n",
      "Accuracy after epoch 14: 0.636315\n",
      "Accuracy after epoch 15: 0.641922\n",
      "Accuracy after epoch 16: 0.649271\n",
      "Accuracy after epoch 17: 0.654998\n",
      "Accuracy after epoch 18: 0.661206\n",
      "Accuracy after epoch 19: 0.667354\n",
      "Accuracy after epoch 20: 0.675485\n",
      "Accuracy after epoch 21: 0.678028\n",
      "Accuracy after epoch 22: 0.682393\n",
      "Accuracy after epoch 23: 0.689262\n",
      "Accuracy after epoch 24: 0.689783\n",
      "Accuracy after epoch 25: 0.693127\n",
      "Accuracy after epoch 26: 0.697232\n",
      "Accuracy after epoch 27: 0.701578\n",
      "Accuracy after epoch 28: 0.705063\n",
      "Accuracy after epoch 29: 0.709348\n",
      "Accuracy after epoch 30: 0.708527\n",
      "Accuracy after epoch 31: 0.712832\n",
      "Accuracy after epoch 32: 0.715576\n",
      "Accuracy after epoch 33: 0.719461\n",
      "Accuracy after epoch 34: 0.723206\n",
      "Accuracy after epoch 35: 0.725709\n",
      "Accuracy after epoch 36: 0.726310\n",
      "Accuracy after epoch 37: 0.728893\n",
      "Accuracy after epoch 38: 0.732878\n",
      "Accuracy after epoch 39: 0.733859\n",
      "Accuracy after epoch 40: 0.736643\n",
      "Accuracy after epoch 41: 0.738305\n",
      "Accuracy after epoch 42: 0.742691\n",
      "Accuracy after epoch 43: 0.744893\n",
      "Accuracy after epoch 44: 0.743512\n",
      "Accuracy after epoch 45: 0.746836\n"
     ]
    }
   ],
   "source": [
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "\n",
    "    # define model\n",
    "    model = define_model()\n",
    "\n",
    "    # create data generator\n",
    "    datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\n",
    "    # prepare iterator\n",
    "    it_train = datagen.flow(trainX, trainY, batch_size=64)\n",
    "\n",
    "    # fit model\n",
    "    steps = int(trainX.shape[0] / 64)\n",
    "\n",
    "    # define a function to print the accuracy after the first epoch\n",
    "    def print_accuracy(epoch, logs):\n",
    "        print('Accuracy after epoch %d: %f' % (epoch+1, logs['accuracy']))\n",
    "\n",
    "    # define the callback\n",
    "    accuracy_callback = LambdaCallback(on_epoch_end=lambda epoch, logs: print_accuracy(epoch, logs))\n",
    "\n",
    "    history = model.fit(it_train, steps_per_epoch=steps, epochs=100, validation_data=(testX, testY), verbose=0, callbacks=[accuracy_callback])\n",
    "\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17304cc4-c429-42f3-81b2-3f808ae2b10c",
   "metadata": {},
   "source": [
    "##  Load and prepare the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a5aa3f-9db0-4d78-8379-fd7706a580ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    # load the image\n",
    "    img = load_img(filename, target_size=(32, 32))\n",
    "    img = img_to_array(img)\n",
    "\n",
    "    # reshape into a single sample with 3 channels\n",
    "    img = img.reshape(1, 32, 32, 3)\n",
    " \n",
    "    # prepare pixel data\n",
    "    img = img.astype('float32')\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "# predict the class\n",
    "result =model.predict_classes(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb33db-04d5-4fe6-90ec-9dfa771f1b39",
   "metadata": {},
   "source": [
    "## Load an image and predict the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae42210-b3c1-4e55-8fca-0b9304234bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_example():\n",
    " \n",
    "    # load the image\n",
    "    img = load_image('sample_image.png')\n",
    " \n",
    "    # load model\n",
    "    model = load_model('final_model.h5')\n",
    " \n",
    "    # predict the class\n",
    "    result = model.predict_classes(img)\n",
    "    print(result[0])\n",
    "\n",
    "run_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
